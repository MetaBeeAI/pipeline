#!/usr/bin/env python3
"""
Test script to demonstrate the parallel processing capabilities of the updated pipeline.
This script shows the hybrid model approach: GPT-4o-mini for relevance scoring (fast) and GPT-4o for answer generation (high quality).
"""

import asyncio
import time
import json
from pathlib import Path
from json_multistage_qa import ask_json, RELEVANCE_MODEL, ANSWER_MODEL, DEFAULT_RELEVANCE_BATCH_SIZE, DEFAULT_ANSWER_BATCH_SIZE

async def test_parallel_processing():
    """Test the parallel processing capabilities with timing information."""
    
    print("üöÄ Testing Parallel Processing Pipeline")
    print("=" * 60)
    print(f"üìä Configuration:")
    print(f"  ‚Ä¢ Relevance Model: {RELEVANCE_MODEL} (Fast)")
    print(f"  ‚Ä¢ Answer Model: {ANSWER_MODEL} (High Quality)")
    print(f"  ‚Ä¢ Relevance Batch Size: {DEFAULT_RELEVANCE_BATCH_SIZE}")
    print(f"  ‚Ä¢ Answer Batch Size: {DEFAULT_ANSWER_BATCH_SIZE}")
    print()
    
    # Test question
    test_question = "What species of bee(s) were tested?"
    
    # Try to get path from config, fallback to hardcoded path
    try:
        import sys
        sys.path.append('..')
        from config import get_papers_dir
        papers_dir = get_papers_dir()
        test_json_path = Path(papers_dir) / "002" / "pages" / "merged_v2.json"
        print(f"üìÅ Using config path: {test_json_path}")
    except ImportError:
        # Fallback to hardcoded path
        test_json_path = Path("/Users/user/Documents/MetaBeeAI_dataset2/papers/002/pages/merged_v2.json")
        print(f"üìÅ Using fallback path: {test_json_path}")
    
    if not test_json_path.exists():
        print(f"‚ùå Test file not found: {test_json_path}")
        return
    
    print(f"ü§î Testing question: {test_question}")
    print(f"üìÑ Using JSON file: {test_json_path}")
    print("-" * 60)
    
    # Test with timing
    start_time = time.time()
    
    try:
        print("‚è≥ Starting pipeline processing...")
        result = await ask_json(test_question, str(test_json_path))
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"‚úÖ Processing completed in {processing_time:.2f} seconds")
        print()
        
        # Display results
        print("üìä Results Summary:")
        print(f"  ‚Ä¢ Answer: {result.get('answer', 'No answer')[:100]}...")
        print(f"  ‚Ä¢ Reason: {result.get('reason', 'No reason')[:100]}...")
        print(f"  ‚Ä¢ Chunk IDs: {len(result.get('chunk_ids', []))} chunks")
        
        if 'relevance_info' in result:
            ri = result['relevance_info']
            print(f"  ‚Ä¢ Total chunks processed: {ri.get('total_chunks_processed', 'N/A')}")
            print(f"  ‚Ä¢ Relevant chunks found: {ri.get('relevant_chunks_found', 'N/A')}")
        
        print()
        print("üîç Performance Analysis:")
        print(f"  ‚Ä¢ Total processing time: {processing_time:.2f}s")
        
        # Estimate speedup from parallel processing
        if 'relevance_info' in result:
            total_chunks = result['relevance_info'].get('total_chunks_processed', 0)
            if total_chunks > 0:
                # Rough estimate: sequential would take ~2s per chunk for relevance + ~3s per chunk for answers
                estimated_sequential_time = total_chunks * 2 + len(result.get('chunk_ids', [])) * 3
                speedup = estimated_sequential_time / processing_time if processing_time > 0 else 0
                print(f"  ‚Ä¢ Estimated sequential time: {estimated_sequential_time:.1f}s")
                print(f"  ‚Ä¢ Parallel processing speedup: {speedup:.1f}x")
        
        print()
        print("üéØ Hybrid Model Benefits:")
        print(f"  ‚Ä¢ Fast relevance scoring with {RELEVANCE_MODEL}")
        print(f"  ‚Ä¢ High-quality answers with {ANSWER_MODEL}")
        print(f"  ‚Ä¢ Parallel processing reduces total time")
        
    except Exception as e:
        print(f"‚ùå Error during testing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("Starting parallel processing test...")
    asyncio.run(test_parallel_processing())
